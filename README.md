# LLM-Powered Candidate Scoring System

This project allows recruiters to submit a job description and receive a ranked list of top candidates based on a preloaded database, scored using an LLM via a FastAPI backend.

---

## ğŸ“ Project Structure

```
/llm-api          â†’ FastAPI backend for LLM scoring
/app              â†’ Next.js frontend and API
  â”œâ”€â”€ /public     â†’ Contains preprocessed candidates.json
  â”œâ”€â”€ /assets     â†’ Raw CSV candidate data
  â””â”€â”€ /scripts    â†’ Build-time processing script
```

---

## ğŸ›  Setup

### 1. Install Dependencies

```bash
npm install
```

### 2. Preprocess Candidate Data

This happens automatically on build, but you can also run it manually:

```bash
npm run prepare:candidates
```

This reads `assets/candidates.csv`, normalizes and deduplicates entries, and outputs `public/candidates.json`.

### 3. Build Frontend

```bash
npm run build
```

To preview output before building:

```bash
npm run preview:candidates
```

---

## ğŸŒ Running Locally

### FastAPI Backend (required for scoring)

```bash
cd llm-api
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### Next.js App

```bash
cd app
npm run dev
```

Make sure the FastAPI backend is running at `http://localhost:8000`.

---

## ğŸŒŸ Environment Variables

Create a `.env.local` file in `/app`:

```env
LLM_BACKEND_URL=http://localhost:8000
```

---

## ğŸ§ª Testing

TBD â€“ add Jest tests for prompt construction, parsing, and API integration.

---

## ğŸ” Candidate Format

The preprocessed candidate file (`candidates.json`) contains objects with:

```ts
interface Candidate {
  id: string;
  name: string;
  jobTitle: string;
  resume: string; // Flattened summary of all fields
}
```

---

## ğŸ§± Built With

* Next.js 15 (TypeScript)
* FastAPI (Python)
* OpenAI (LLM Scoring)
* CSV + HTML cleaning utilities

---

## ğŸ“¦ Deployment

* Frontend can be deployed on Vercel
* FastAPI backend must be deployed separately (e.g. Render, Fly.io)

---

## ğŸ“„ License

MIT
